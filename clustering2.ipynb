{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZGgsgRN9ZkFloWeNpswnG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WiemHAD/clustering/blob/master/clustering2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6S5MedET42V"
      },
      "source": [
        "Applying Kmeans algorith to emotion data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wrhfJqhxZAP",
        "outputId": "e38c9cfc-70b5-40cb-9ce9-d91e6d9fa67e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGvfH-s9xdwU"
      },
      "source": [
        "#global variables\n",
        "df = pd.read_csv('emotion.csv')\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "targets = df['Emotion']\n",
        "corpus = df['Text']\n",
        "# count vectorizer using SKlearn\n",
        "vect = CountVectorizer(stop_words = stopwords)\n",
        "X = vect.fit_transform(corpus)\n",
        "words = vect.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jNivtuy6UF3"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQHVN1xVxzaS"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters = 6)\n",
        "kmeans_fitted = kmeans.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0xqSpCXzRRb",
        "outputId": "8d9a0a78-2a0f-4ad0-bbf1-3493f6059fbd"
      },
      "source": [
        "from sklearn.metrics.cluster import adjusted_mutual_info_score, homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score\n",
        "print('AMI score = ', adjusted_mutual_info_score(kmeans.labels_,targets))\n",
        "print('homogeneity score =', homogeneity_score(kmeans.labels_,targets))\n",
        "print('completeness_score = ',completeness_score(kmeans.labels_,targets))\n",
        "print('V measure score =', v_measure_score(kmeans.labels_,targets))\n",
        "print('Adjusted Rand Score =', adjusted_rand_score(kmeans.labels_, targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AMI score =  0.007869351582768509\n",
            "homogeneity score = 0.009155314711364874\n",
            "completeness_score =  0.007541844560975775\n",
            "V measure score = 0.00827062368319247\n",
            "Adjusted Rand Score = 0.010184088402371496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NPYyG3Q0tm3"
      },
      "source": [
        "from time import time\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def bench_k_means(kmeans, name, data, labels):\n",
        "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    kmeans : KMeans instance\n",
        "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
        "        already set.\n",
        "    name : str\n",
        "        Name given to the strategy. It will be used to show the results in a\n",
        "        table.\n",
        "    data : ndarray of shape (n_samples, n_features)\n",
        "        The data to cluster.\n",
        "    labels : ndarray of shape (n_samples,)\n",
        "        The labels used to compute the clustering metrics which requires some\n",
        "        supervision.\n",
        "    \"\"\"\n",
        "    t0 = time()\n",
        "    estimator = make_pipeline(StandardScaler(with_mean=False), kmeans).fit(data)\n",
        "    fit_time = time() - t0\n",
        "    results = [name, fit_time, estimator[-1].inertia_]\n",
        "\n",
        "    # Define the metrics which require only the true labels and estimator\n",
        "    # labels\n",
        "    clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score,\n",
        "    ]\n",
        "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
        "\n",
        "    # The silhouette score requires the full dataset\n",
        "    results += [\n",
        "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
        "                                 metric=\"euclidean\")\n",
        "    ]\n",
        "\n",
        "    # Show the results\n",
        "    formatter_result = (\"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
        "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\")\n",
        "    print(formatter_result.format(*results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpd7iYVc07or",
        "outputId": "0fb45634-8cd1-4744-a8cf-d56acb6f4be5"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "print(82 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=6,\n",
        "                random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=X, labels=targets)\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=6,random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=X, labels=targets)\n",
        "\n",
        "\n",
        "clf = TruncatedSVD()\n",
        "Xpca = clf.fit_transform(X)\n",
        "XX = PCA(2).fit_transform(Xpca)\n",
        "kmeans = KMeans(n_clusters=6, n_init=1)\n",
        "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=XX, labels=targets)\n",
        "print(82 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
            "k-means++\t8.258s\t408284055\t0.000\t0.119\t0.000\t-0.000\t-0.000\t0.200\n",
            "random   \t13.563s\t408847945\t0.002\t0.110\t0.004\t-0.001\t0.003\t0.007\n",
            "PCA-based\t0.060s\t6440\t0.007\t0.008\t0.008\t0.010\t0.008\t0.642\n",
            "__________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq8a2HOoKfOg"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS_nDY4eLoqT",
        "outputId": "45e75cb8-a12a-4778-9542-9b398b8b7d4d"
      },
      "source": [
        "print(82 * '_')\n",
        "print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=6, n_init=4,\n",
        "                random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=X_tfidf, labels=y)\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=6, n_init=4, random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=X_tfidf, labels=y)\n",
        "\n",
        "clf = TruncatedSVD()\n",
        "Xpca = clf.fit_transform(X)\n",
        "XX_tfidf = PCA(2).fit_transform(Xpca)\n",
        "kmeans = KMeans(n_clusters=6, n_init=1)\n",
        "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=XX_tfidf, labels=y)\n",
        "print(82 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________\n",
            "init\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\n",
            "k-means++\t11.775s\t411236170\t0.003\t0.152\t0.006\t-0.002\t0.005\t-0.007\n",
            "random   \t6.429s\t412060564\t0.000\t0.073\t0.001\t-0.000\t0.000\t-0.009\n",
            "PCA-based\t0.046s\t4532\t0.007\t0.008\t0.007\t0.010\t0.007\t0.675\n",
            "__________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UzWxkkfY1kC"
      },
      "source": [
        "* Est-que les clusters obtenue avec kmeans reflete les groupements de texte par émotions ?\n",
        "\n",
        "au vu des résultats obtenus, les clusters obtenus ne refléte pas les groupements de texte par émotions.\n",
        "\n",
        "* Quelle est le nombre de cluster optimal au regard de la métrique \"silhouette\" ? de l'inertie ?  est ce que l'inertie est corrélé à la mesure de silhouette ?\n",
        "\n",
        "on observe, sur les différents tableaux de résultats que:\n",
        "- l'inertie est inversement proportionnelle aux autres metriques. \n",
        "- en combinant le TF-IDF, Truncated SVD et PCA, on obtient des meilleurs résultats. \n",
        "- le TF-IDF a permi d'améliorer la silhouette du random et du PCA mais celle du kmeans++ s'est dégradée.\n",
        "- étant donnée que la metrique silhouette n'est pas révélatrice, le nombre de cluster doit être plus important\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXDBxyqPYpab"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0yfnGGudP3c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}